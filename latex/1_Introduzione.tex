% - Introduzione (contesto: power management, hpc, dds)
%   - problematica 
%   - contributi ( lista della spesa )
%   non eccessivamente lunga
\chapter{Introduzione}
% HPC ============================================================================
%Perchè HPC
Nel panorama scientifico e industriale contemporaneo, assistiamo ad una sempre più crescente domanda di capacità computazionali, alimentata anche dalla necessità di gestire, monitorare e analizzare ingenti quantità dati. Infatti ambiti come simulazioni complesse, meteorologia, calcolo in tempo reale e le nuove realtà di intelligenza artificiale sono rese possibili solo grazie a tecnologie il cui unico scopo è quello di risolvere problemi avanzati in tempi brevi. In particolare si parla di High Performance Computing (HPC), o calcolo ad elevate prestazioni, di quelle tecnologie che utilizzano cluster di processori e componenti hardware ad alte prestazioni in grado di processare dati multidimensionali in modo simultaneo.
% Come funziona?
I sistemi di \emph{High Performance Computing}, per poter sopperire a queste richieste, necessitano di diversi nodi di calcolo, ognuno dei quali è composto da molteplici processori come CPU, GPU o TPU e memorie ad alte prestazioni. Questi nodi solitamente sono collegati tra loro da reti ad alta velocità che permettono sia ai software di schedulazione di suddividere i workflow in diversi nodi, che ai diversi job di comunicare durante la loro esecuzione. Inoltre per poter funzionare al meglio questi cluster solitamente sono supportati da sistemi di raffreddamento in grado gestire le notevoli quantità di calore che prodotte dalle attività di calcolo. 

% Ovviamente tutto questo ha un costo, e in questo ultimo decennio si sono manifestate delle sempre crescenti richieste di capacità e potenza computazionale mentre le tecnologie ad esse associate si sono avvicinate ai propri limiti fisici.
% Problema degli HPC
La gestione energetica di sistemi HPC è diventata per questo motivo, una delle principali preoccupazioni, non solo a causa dei costi monetari, ma anche per la sostenibilità ambientale e per la progettazione di nuove generazioni\cite{TODO} di supercomputer. Infatti perpendicolarmente all'aumento della potenza computazionale richiesta, le tecnologie associate allo sviluppo dei componenti primari dei processori, i componenti più energivori del sistema, si sono avvicinati ai loro limiti fisici.
% Dennard ========================================================================
Questi ultimi hanno portato a delle difficoltà sempre più grandi nel ridimensionamento dei transistor, conseguito nella progressiva fine delle leggi di Denard e Moore\cite{TODO}. Tali leggi, che avevano guidato l'industria informatica per decenni, prevedevano un consumo energetico costante al crescere della velocità e capacità computazionale. Quando questi sono venuti a mancare, il mantenimento e ancora di più lo sviluppo di nuove generazioni di sistemi è diventato un compito tutt'altro che banale, e con questi si sono resi necessari sempre più software in grado di automatizzarne la gestione. 
Infatti utilizzare efficientemente l'energia disponibile e ottimizzare le prestazioni delle applicazioni sotto un limite di potenza è diventata una sfida, che ha richiesto soluzioni specifiche. %da sistemare
% Power management ================================================================
Il concetto di Power Management è nato sotto questo contesto, definendo un modello software che ha il compito di gestire tutto ciò che riguarda potenza, energia e temperatura di sistemi di HPC. Per farlo sono stati definiti diversi attori ognuno con un compito specifico, e cercando di standardizzare le interazioni che questi componenti dovevano avere.

Questo Power-Stack ha però la necessità di avere una visione globale per la gestione energetica, al fine di permettere dove necessario di definire degli obbiettivi e limiti di prestazioni e consumi. Inoltre deve essere definita un'interfaccia standard per poter interagire con i controlli hardware e software di sistemi HPC di diversi produttori.
%Una limitazione primaria della maggior parte, se non di tutti, di questi sforzi è che la ricerca sull'ottimizzazione è stata limitata esclusivamente ai singoli livelli del PowerStack. Le opportunità di ottenere ulteriori miglioramenti nell'efficienza energetica dalla messa a punto collettiva di due o più livelli del PowerStack sono rimaste in gran parte inesplorate.
% Problema =======================================================================
Mentre sono state proposte diverse tecniche per colmare questo bisogno, %o mancanza?
%gestione della potenza e dell'energia, 
la maggior parte di esse si è rivelata essere una soluzione per soddisfare singoli obiettivi di ottimizzazione o per un singolo sistema di HPC. Infatti molti dei prodotti attualmente disponibili svolgono compiti a granularità diverse e spesso in conflitto gli uni con gli altri. Peraltro non sono neanche mai state definite o modellizzate interfacce di comunicazione tra i vari software, lasciando ai gestori dei sistemi di HPC, l'onere di farlo.
%TODO: Trovare queste cit:
%Un recente studio [22] condotto dal gruppo di lavoro EEHPC [9] ha concluso che la maggior parte di tali tecniche manca di una consapevolezza globale necessaria per ottenere le migliori prestazioni di sistema e throughput. Inoltre, ciascuna tecnica tende a migliorare la gestione di potenza ed energia per un sottoinsieme diverso dell'hardware del sito o del sistema e a diverse granularità (spesso in conflitto). Sfortunatamente, le tecniche esistenti non sono state progettate per coesistere simultaneamente su un unico sito e cooperare nella gestione in modo efficiente. %Traduzione GPT di paper PS, da cambiare
% Per affrontare queste lacune, la comunità HPC ha bisogno di uno stack completo per la gestione di energia e potenza. 
% DDS =======================================================================
L'obiettivo finale sarebbe infatti quello di fornire un middleware documentato e facilmente integrabile, nei vari strumenti ad oggi presenti, per collegarli tra loro utilizzando un approccio distribuito e sfruttando il potenziale del Data Distribution Service (DDS)%[\ref{SEC:dds}]
nonché quello di Real-Time Publish-Subscribe (RTPS).


\section{Contributi}
I contributi di questa tesi sono stati lo studio e caratterizzazione di una specifica implementazione di DDS all'interno di sistemi HPC al fine di fornire una visione più completa della possibilità di integrare questo strumento come base delle comunicazioni di un middlware per i componenti del power management. Successivamente sono stati valutati dei modelli basati su questi risultati come modo d'uso. Infine sono stati creati per completare il quadro due di questi attori, mancanti nelle implementazioni attualmente prodotte, utilizzando la libreria REGALE.

- Definire le interfacce tra questi livelli per tradurre gli obiettivi a ciascun livello in azioni al livello inferiore adiacente.
- Promuovere l'ottimizzazione end-to-end attraverso diversi livelli del PowerStack.
% Negli ultimi anni, la rapida crescita dei sistemi di supercalcolo ha portato a una crescente domanda di strategie efficienti per il power management. Poiché il panorama delle capacità omputazionali continua la sua rapida espansione, l'imperativo di soluzioni  sostenibili di gestione dell'energia diventa ancora più evidente. La formidabile potenza computazionale esercitata dai moderni supercomputer è spesso contrastata dal considerevole consumo di energia necessario per alimentare le loro operazioni. Questo fenomeno è evidente anche nell'interesse crescente per il calcolo ecologico, anziché il puro e semplice consumo di energia\cite{Green}\cite{Green2}\cite{hardvard}. In questo contesto, la ricerca di innovative strategie di gestione dell'energia diventa non solo una considerazione economica, ma soprattutto uno sforzo fondamentale per ridurre le conseguenze ecologiche dell'incremento del consumo di energia. Inoltre, le prestazioni degli elementi di calcolo sono intrinsecamente limitate dal consumo di energia, il che implica che migliorare l'efficienza energetica si traduce in una maggiore performance massima.

% Le architetture moderne implementano un controllore termico e energetico integrato nel dado, il cui scopo è fornire prestazioni massime entro limiti fisici ed esternamente imposti. Oltre a ciò, sono stati aggiunti anche altri compiti al controllo energetico e termico, tra cui:
% (i) scambio di messaggi con diversi agenti (come Node-manager, Board Management Controller (BMC) e sistemi operativi) modificando la sua azione di controllo per soddisfare tutti i vincoli dati da questi agenti;
% (ii) essere consapevoli delle implicazioni sulla sicurezza delle sue azioni di controllo, evitando punti operativi fatali a livello di sistema e rilevando e prevenendo attacchi basati sulla sicurezza legati a errori\cite{fbv} o a rumori elettrici virus\cite{pnv}.

% Inoltre, c'è la mancanza di software completi, interoperabili e open-source in grado di gestire e monitorare contemporaneamente il consumo senza influire sull'aspetto più cruciale dei supercomputer: le prestazioni. Attualmente, ci sono diverse utility [\ref{SSEC:runtimes}] capaci di risolvere un dominio di problemi, ma senza la capacità di interagire tra loro in modo diretto.

% L'obiettivo finale sarebbe infatti quello di collegare gli strumenti diversi disponibili utilizzando un approccio distribuito, sfruttando il potenziale del Data Distribution Service (DDS) e del Real-Time Publish-Subscribe (RTPS).% [\ref{SEC:dds}].

% \subsection{DDS \& RTPS} \label{SEC:dds}
% DDS (Data Distribution Service)\cite{DDS} e RTPS (Real-Time Publish-Subscribe)\cite{RTPS} costituiscono due tecnologie fondamentali nel campo delle comunicazioni distribuite e in tempo reale. Queste tecnologie svolgono un ruolo critico nel consentire una trasmissione efficiente e affidabile dei dati tra dispositivi e applicazioni interconnesse, con particolare rilevanza in scenari complessi come i sistemi embedded, l'Internet delle cose e applicazioni ad alte prestazioni come l'HPC.

% In particolare, DDS funge da framework di comunicazione distribuita che facilita lo scambio di dati tra componenti software distribuiti su reti eterogenee e consente di definire la politica di qualità del servizio (QoS). D'altra parte, RTPS funge da protocollo sottostante utilizzato da DDS per realizzare il paradigma di pubblicazione-sottoscrizione all'interno delle reti in tempo reale. RTPS si concentra sulla consegna affidabile di messaggi in tempo reale, garantendo che i dati raggiungano i destinatari appropriati nel modo più efficiente possibile. Questo protocollo gestisce anche aspetti critici come il controllo del flusso dei dati e la sincronizzazione dei nodi.
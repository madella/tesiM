% - Introduzione (contesto: power management, hpc, dds)
%   - problematica 
%   - contributi ( lista della spesa )
%   non eccessivamente lunga
\chapter{Introduzione}
% HPC ============================================================================
%Perchè HPC
Nel panorama scientifico e industriale contemporaneo, assistiamo ad una sempre più crescente domanda di capacità computazionali, alimentata anche dalla necessità di gestire, monitorare e analizzare ingenti quantità dati. Infatti ambiti come simulazioni complesse, meteorologia, calcolo in tempo reale e le nuove realtà di intelligenza artificiale sono rese possibili solo grazie a tecnologie il cui unico scopo è quello di risolvere problemi 
avanzati in tempi brevi. 
% Cos'è
Si parla di High Performance Computing (HPC), di quelle tecnologie che utilizzano cluster di processori e componenti hardware ad alte prestazioni in grado di processare parallelamente dati multidimensionali.
% Come funziona?
In particolare, sono composte da cluster di nodi, ognuno dei quali contiene diverse decine di processori ed acceleratori collegati tra di loro da reti ad alta banda.
Inoltre per poter funzionare al meglio questi cluster solitamente sono supportati da sistemi di raffreddamento in grado gestire le notevoli quantità di calore che prodotte dalle attività di calcolo. 

% Problema degli HPC
La gestione energetica di questi sistemi è diventata per questo motivo, una delle principali preoccupazioni, non solo a causa dei costi monetari, ma anche per la sostenibilità ambientale e per la progettazione di nuove generazioni di supercomputer\cite{TODO}. Infatti perpendicolarmente all'aumento della potenza computazionale richiesta, le tecnologie associate allo sviluppo dei componenti primari dei processori (quelli più energivori) si sono avvicinati ai loro limiti fisici.
% Dennard ========================================================================
Nello specifico si sono manifestate delle difficoltà sempre più grandi nel ridimensionamento dei transistor, che ha portato ad una progressiva fine delle leggi di Denard e Moore\cite{TODO}. Tali leggi, che avevano guidato l'industria informatica per decenni, prevedevano un consumo energetico costante al crescere della velocità e capacità computazionale. Quando la loro efficacia è venuta a mancare, il mantenimento e ancora di più lo sviluppo di nuove generazioni di sistemi sono diventati compiti tutt'altro che banali, rendendo sempre più di vitale importanza i software in grado di automatizzarne la gestione. %Infatti utilizzare efficientemente l'energia disponibile e ottimizzare le prestazioni delle applicazioni sotto un limite di potenza è diventata una sfida, che ha richiesto soluzioni specifiche. %da sistemare
% Power management ================================================================
Il concetto di Power Management è nato sotto questo contesto, cercando di definire un modello software che ha il compito di gestire la potenza, energia e temperatura di sistemi di HPC. Per farlo sono stati definiti diversi attori ognuno con un compito specifico, e cercando di standardizzare le interazioni che i componenti dovevano avere tra di loro.
Questo Power Stack ha però la necessità di avere una visione globale per la gestione energetica, al fine di permettere dove necessario di definire degli obbiettivi e limiti di prestazioni e consumi. Inoltre deve essere definita un'interfaccia standard per poter interagire con i controlli hardware e software di sistemi HPC di diversi produttori.
%Una limitazione primaria della maggior parte, se non di tutti, di questi sforzi è che la ricerca sull'ottimizzazione è stata limitata esclusivamente ai singoli livelli del PowerStack. Le opportunità di ottenere ulteriori miglioramenti nell'efficienza energetica dalla messa a punto collettiva di due o più livelli del PowerStack sono rimaste in gran parte inesplorate.
% Problema =======================================================================
Mentre sono state proposte diverse tecniche per colmare questo bisogno, %o mancanza?
%gestione della potenza e dell'energia, 
la maggior parte di esse si è rivelata essere una soluzione per soddisfare singoli obiettivi di ottimizzazione o per un singolo sistema di HPC. Infatti molti dei prodotti attualmente disponibili svolgono compiti senza una visione globale e spesso in conflitto gli uni con gli altri. Peraltro non sono neanche mai state definite o modellizzate interfacce di comunicazione tra i vari software, lasciando agli amministratori dei sistemi di HPC, l'onere di farlo.
%TODOV: Trovare queste cit: M. Maiterth et al., Energy and power aware job scheduling and resource management: global survey initial analysis, in 2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), Vancouver, BC, 2018, pp. 685–693, doi: 10.1109/IPDPSW.2018.00111.
%Un recente studio [22] condotto dal gruppo di lavoro EEHPC [9] ha concluso che la maggior parte di tali tecniche manca di una consapevolezza globale necessaria per ottenere le migliori prestazioni di sistema e throughput. Inoltre, ciascuna tecnica tende a migliorare la gestione di potenza ed energia per un sottoinsieme diverso dell'hardware del sito o del sistema e a diverse granularità (spesso in conflitto). Sfortunatamente, le tecniche esistenti non sono state progettate per coesistere simultaneamente su un unico sito e cooperare nella gestione in modo efficiente. %Traduzione GPT di paper PS, da cambiare
% Per affrontare queste lacune, la comunità HPC ha bisogno di uno stack completo per la gestione di energia e potenza. 
% DDS =======================================================================
L'obiettivo finale sarebbe infatti quello di fornire un middleware documentato e facilmente integrabile, nei vari strumenti ad oggi presenti, per collegarli tra loro utilizzando un approccio distribuito e sfruttando il potenziale del Data Distribution Service (DDS) %[\ref{SEC:dds}] 
nonché quello di Real-Time Publish-Subscribe (RTPS).

\section{Contributi}
I contributi di questa tesi sono stati lo studio e caratterizzazione di una specifica implementazione di DDS all'interno di sistemi HPC al fine di fornire una visione più completa della possibilità di integrare questo strumento come base delle comunicazioni di un middlware per i componenti del power management. Successivamente sono stati valutati dei modelli basati su questi risultati come modo d'uso. Infine sono stati creati per completare il quadro due di questi attori, mancanti nelle implementazioni attualmente prodotte, utilizzando la libreria REGALE.

% - Definire le interfacce tra questi livelli per tradurre gli obiettivi a ciascun livello in azioni al livello inferiore adiacente.
% - Promuovere l'ottimizzazione end-to-end attraverso diversi livelli del PowerStack.

% ==============================================================  obbiettivi di power management.
% Formalmente energy management, power management e thermal management hanno significati diversi.

% Power management -> gestione della Potenza. Qui l’obbiettivo è controllare la potenza assorbita. Indirettamente legata al raffreddamento (qui di parla di TDP - thermal design power – si fa l’assunzione di essere a regime, quindi a transitori termici esaurit), ma anche legata alla massima corrente erogabile da un alimentatore o dai pad del chip. In questo caso si parla di TDC, Thermal design current ma anche di peak current.

% Quando si parla di TDP o TDC di norma quello che si vuole ottenere è fare power capping ovvero limitare la max power ad un certo valore. 
% Se si parla invece di power management si può in modo erraneo anche includere energy management 

% Thermal management -> gestione temperatura dinamica o statica. 
% Energy management -> gestione dell’energia e quindi anche di quello che si paga, e sostenibilità. Qui bisogna stare attenti in quanto l’estremo dell’energy management e riduzione del costo energetico è quello di spegnere tutto e andare al mare. Ovvero se non si fa compute o se si va molto piano si paga una penalità in performance molto elevata. Essendo un problema di trade off tra performance e riduzione dei consumi spesso si deve darsi una definizione di quella che è una performance accettabile o una riduzione di performance accettabile dentro la quale si cerca di ridurre l’energia. 
%Fissata la riduzione di performance, minimizzare l’energia coincide con minimizzare la potenza. Da qui la confusione tra energy management e power management.

% E’ doveroso differenziare tra energia e potenza in quanto ridurre la potenza non vuol dire per forza ridurre l’energia, e viceversa. Sono infatti famose due politiche, run fast and stop e go slow and low power. Ma qui ci arrivo dopo.
% A volte si usa power management per includere tutti i tre, thermal, power e energy. In modo erraneo giusto?

% Meccanismi e componenti HW per il power management, ma anche thermal ed energy.

% DFS: Dynamic Frequency scaling. Questo vuol dire che da qualche parte nell’archietettura c’è un registro che permette di cambiare la frequenza del PLL o FLL che eroga il clock alla CPU. Riducendo la frequenza di clock si ha un effetto lineare sulla riduzione della potenza dinamica.
% Clock gating: da qualche parte nell’albero di clock c’è l’equivalente di un AND che può essere comandato tramite registro (throttling) o in modo automatico per silenziare il segnale di clock. Questo azzera la potenza dinamica.
% Throttling – anche T state in terminologia ACPI. Questo vuol dire che è possibile salare dei cicli di clock in modo percentuale. Equivalente a DFS ma non proprio.
% DVFS: Dynamic voltage e frequency scaling. In questo caso si varia anche il voltaggio insieme alla frequenza. Facendo ciò si riduce fino al cubo la potenza dinamica, si riduce in modo esponenziale il leakage. Aumenta il costo di design in quanto deve essere fatto il sign-off del core a diverse coppie di frequenza e tensione.  E’ necessario poter variare la tensione per delle zone del chip.  Servono o voltage regulator che permettono di variare la tensione, oppure degli LDO che sfruttano transistor per controllare un drop di tensione. A seconda dell’implementazione può essere il core a settare la nuova tensione e frequenza oppure un controllore di potenza. Vedi i P-state.
% Power gating, o anche C-state. In questo caso viene rimossa l’aliomentazione ai core. A seconda dell’implementazione serve salvare il contesto o meno.
% Power capping (RAPL) in questo caso esiste un registro che permette di fissare un consumo massimo per alcune sotto parti del chip. In realtà è realizzato da un controllore di potenza che tramite firmware controlla le manopole di sopra.
% PVT sensors, process, voltage e temperature sensor. Servono per misurare la velocità del silicio, la tensione e la temperatura in zone del silicio.
 

% Algoritmi: % Come sfrutti le manopole di sopra per realizzare i goal di ancora più sopra.
% Esempi sono Countdown, EAR, linux governors, ecc ecc.
 

% Una parte fondamentale di tutti gli algoritmi di energy management è capire preventivamente di quanto si rallenterà l’applicazione riducendo le performance (frequency scaling o throttlingo o power capping RAPL). Questo perché non sempre è conveniente andare piano. Il motivo è il leakage e la potenza statica.

 
# Blueprint

We mainly have 2 benchmarking methods:
- Exchanged packets -> `tcpdump`
- Resource consumption -> `perf`

with the resulting folders `packets` and `performance`.

Within each of these folders, the following files are present:
- `automated_perf.sh`
- `graph_generator.py`
- `perf_monitor.sh`

#### automated_perf.sh

It is responsible for starting multiple instances of `perf_monitor.sh` with different parameters and exporting environment variables for the Python script.

```bash
for ((i=1; i<=$RANGE; i+=$GRANULARITY))
do
    echo "Entering test with $i node"
    # In this case, perf was started to monitor different protocols
    perf stat -o $file1 ./perf_monitor.sh ${i} $PROTOCOL1 $PARTITIONS
    
    perf stat -o $file2 ./perf_monitor.sh ${i} $PROTOCOL2 $PARTITIONS

done
# Automatic launch graph-generator
python3 graph_generator.py 
```

#### graph_generator.py
It is responsible for processing data and generating graphs.
``` python
# Specific data processing for tcpdump
def count_packets(filename):
    command = 'tshark -r {} -Y'.format(filename)
    command += ' "rtps && ('
    command += ' (rtps.sm.rdEntityId == 0x000002c2) ||'
    command += ' (rtps.sm.rdEntityId == 0x000002c7) ||'
    command += ' (rtps.sm.rdEntityId == 0x000003c2) ||'
    command += ' (rtps.sm.rdEntityId == 0x000003c7) ||'
    command += ' (rtps.sm.rdEntityId == 0x000004c2) ||'
    command += ' (rtps.sm.rdEntityId == 0x000004c7) ||'
    command += ' (rtps.sm.rdEntityId == 0x000100c2) ||'
    command += ' (rtps.sm.rdEntityId == 0x000100c7) ||'
    command += ' (rtps.sm.rdEntityId == 0x000200C2) ||'
    command += ' (rtps.sm.rdEntityId == 0x000200C7) ||'
    command += ' (rtps.sm.rdEntityId == 0x000201C3) ||'
    command += ' (rtps.sm.rdEntityId == 0x000201C4))" | wc -l'
    res = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)
    n_packets = int(res.communicate()[0].decode().rstrip())
    return n_packets


# Specific data processing for perf
def extract_data_from_file(file_path):
    task_clock_match = re.search(r'([\d.]+,\d+)\s+msec task-clock', content)
    cycles_match = re.search(r'([\d.]+)\s+cycles', content)
    instructions_match = re.search(r'([\d.]+)\s+instructions', content)
    seconds_elapsed_match = re.search(r'(\d+,\d+)\s+seconds time elapsed', content)
    seconds_user_match = re.search(r'(\d+,\d+)\s+seconds user', content)
    seconds_sys_match = re.search(r'(\d+,\d+)\s+seconds sys', content)
    [...]
    return task_clock, cycles, instructions, time_elapsed, seconds_user, seconds_sys
``` 
#### perf_monitor.sh
This script monitors and starts instances of fastdds specific to a certain test.
``` bash
for (( j=0; j < $PARTITIONS; j++)); do
    # Managing a variable PUBID*J* for later wait
    var_name="PUBPID$j"
    # Starting the subscribers
    for (( i=0; i < $(( $N_OF_TEST / $PARTITIONS )); i++)); do
        $PROTB1/sub $j &
    done
    # Starting a single publisher
    $PROTB1/pub $j &
    # Saving the publisher's pid for later wait
    save=$!
    eval "$var_name=$save"

``` 
#### other files

Additionally, after running these scripts, the data will be stored in the `data/` folder, and the images generated by the Python script will be placed in the `img/` folders
# Results
[Weekly Update](./W_UPDATE.md)

# Error

2023-07-18 11:44:10.400 [RTPS_TRANSPORT_SHM Error] Failed init_port fastrtps_port7610: open_and_lock_file failed -> Function open_port_internal
